{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ.ME\n",
    "\n",
    "Here are two ways to evaluate my model.\n",
    "\n",
    "No.1 is following all the phase.\n",
    "No.2 is using road.tar.gz file.\n",
    "\n",
    "But there is a complex step to make it clear,\n",
    "so I suggest you just to see No.1,    \n",
    "but use road.tar.gz file easily.\n",
    "\n",
    "You can go section '1. Let's go with docker' directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Dataset\n",
    "\n",
    "# Dataset downloading\n",
    "Download the dataset for training and testing the object detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cd djplace/practice/RoadDamageDetector/\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "!wget https://mycityreport.s3-ap-northeast-1.amazonaws.com/02_RoadDamageDataset/public_data/IEEE_bigdata_RDD2020/train.tar.gz\n",
    "\n",
    "!tar -xzvf train.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset pre-processing\n",
    "Remove the useless labels in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the train directory\n",
    "\n",
    "%cd train\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from shutil import copyfile\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "!tree -d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "countries = [\"Czech\", \"India\", \"Japan\"]\n",
    "labels = [\"D00\", \"D10\", \"D20\", \"D40\"]\n",
    "\n",
    "for country in countries:\n",
    "    annoFiles = os.listdir(os.path.join(os.getcwd(), country+\"/annotations/xmls/\"))\n",
    "    jpgFiles = os.listdir(os.path.join(os.getcwd(), country+\"/images/\"))\n",
    "    \n",
    "    newCountry = \"new_\"+country\n",
    "    Path(newCountry+\"/Annotations\").mkdir(parents=True, exist_ok=True)\n",
    "    Path(newCountry+\"/JPEGImages\").mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for annoFile in annoFiles:\n",
    "        tree = ET.parse(os.path.join(os.getcwd()+\"/\"+country+\"/annotations/xmls/\", annoFile))\n",
    "        root = tree.getroot()\n",
    "        for obj in root.findall(\"object\"):\n",
    "            a = obj.find(\"name\").text\n",
    "            if a not in labels:\n",
    "                root.remove(obj)\n",
    "            \n",
    "        if len(root.findall(\"object\")) > 0:\n",
    "            tree.write(newCountry+\"/Annotations/\"+annoFile)\n",
    "            copyfile(os.path.join(country+\"/images/\", annoFile.split(\".\")[0])+\".jpg\", newCountry+\"/JPEGImages/\"+annoFile.split(\".\")[0]+\".jpg\")\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy them into the one directory for chaning to yolo format\n",
    "\n",
    "Path(\"new_train/Annotations\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"new_train/JPEGImages\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "!cp new_Czech/Annotations/*.xml new_train/Annotations/\n",
    "!cp new_India/Annotations/*.xml new_train/Annotations/\n",
    "!cp new_Japan/Annotations/*.xml new_train/Annotations/\n",
    "\n",
    "!cp new_Czech/JPEGImages/*.jpg new_train/JPEGImages/\n",
    "!cp new_India/JPEGImages/*.jpg new_train/JPEGImages/\n",
    "!cp new_Japan/JPEGImages/*.jpg new_train/JPEGImages/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform to YOLO format from VOC xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annoFiles = os.listdir(os.path.join(os.getcwd(), \"train/new_train/Annotations/\"))\n",
    "yoloFile = open(\"./xml2yolo_damage.txt\", \"w\")\n",
    "for i in range(len(annoFiles)):\n",
    "    yoloFile.writelines(os.getcwd() + \"/train/new_train/Annotations/\" + annoFiles[i] + \"\\n\")\n",
    "\n",
    "yoloFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python xml2yolo.py --input-file xml2yolo_damage.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"road/damage\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "!cp train/new_train/JPEGImages/*.jpg road/damage/\n",
    "!cp train/new_train/labels/*.txt road/damage/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the dataset for training the dataset\n",
    "Split the dataset to train dataset and validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the train directory\n",
    "\n",
    "%cd train\n",
    "\n",
    "!tree -d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_Czech_annoFiles = os.listdir(os.path.join(os.getcwd(), \"new_Czech/JPEGImages/\"))\n",
    "print(len(new_Czech_annoFiles))\n",
    "\n",
    "new_India_annoFiles = os.listdir(os.path.join(os.getcwd(), \"new_India/JPEGImages/\"))\n",
    "print(len(new_India_annoFiles))\n",
    "\n",
    "new_Japan_annoFiles = os.listdir(os.path.join(os.getcwd(), \"new_Japan/JPEGImages/\"))\n",
    "print(len(new_Japan_annoFiles))\n",
    "\n",
    "Czech_train, Czech_valid = train_test_split(new_Czech_annoFiles, test_size=0.2, random_state=42)\n",
    "print(len(Czech_train), len(Czech_valid))\n",
    "\n",
    "India_train, India_valid = train_test_split(new_India_annoFiles, test_size=0.2, random_state=42)\n",
    "print(len(India_train), len(India_valid))\n",
    "\n",
    "Japan_train, Japan_valid = train_test_split(new_Japan_annoFiles, test_size=0.2, random_state=42)\n",
    "print(len(Japan_train), len(Japan_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single source training dataset\n",
    "\n",
    "file1 = open(\"../road/Cz_8_train.txt\", \"w\")\n",
    "for i in range(len(Czech_train)):\n",
    "    file1.writelines('/usr/src/road/damage/' + Czech_train[i].split(\".\")[0] + '.jpg' + \"\\n\")\n",
    "\n",
    "file1.close()\n",
    "\n",
    "file2 = open(\"../road/Cz_2_valid.txt\", \"w\")\n",
    "for i in range(len(Czech_valid)):\n",
    "    file2.writelines('/usr/src/road/damage/' + Czech_valid[i].split(\".\")[0] + '.jpg' + \"\\n\")\n",
    "\n",
    "file2.close()\n",
    "\n",
    "file1 = open(\"../road/In_8_train.txt\", \"w\")\n",
    "for i in range(len(India_train)):\n",
    "    file1.writelines('/usr/src/road/damage/' + India_train[i].split(\".\")[0] + '.jpg' + \"\\n\")\n",
    "\n",
    "file1.close()\n",
    "\n",
    "file2 = open(\"../road/In_2_valid.txt\", \"w\")\n",
    "for i in range(len(India_valid)):\n",
    "    file2.writelines('/usr/src/road/damage/' + India_valid[i].split(\".\")[0] + '.jpg' + \"\\n\")\n",
    "\n",
    "file2.close()\n",
    "\n",
    "file1 = open(\"../road/Ja_8_train.txt\", \"w\")\n",
    "for i in range(len(Japan_train)):\n",
    "    file1.writelines('/usr/src/road/damage/' + Japan_train[i].split(\".\")[0] + '.jpg' + \"\\n\")\n",
    "\n",
    "file1.close()\n",
    "\n",
    "file2 = open(\"../road/Ja_2_valid.txt\", \"w\")\n",
    "for i in range(len(Japan_valid)):\n",
    "    file2.writelines('/usr/src/road/damage/' + Japan_valid[i].split(\".\")[0] + '.jpg' + \"\\n\")\n",
    "\n",
    "file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix source training dataset\n",
    "\n",
    "CzInJa_train = new_Czech_annoFiles + new_India_annoFiles + Japan_train\n",
    "random.shuffle(CzInJa_train)\n",
    "\n",
    "CzInJa_valid = Japan_valid\n",
    "random.shuffle(CzInJa_valid)\n",
    "\n",
    "file1 = open(\"../road/CzInJa_train.txt\", \"w\")\n",
    "for i in range(len(CzInJa_train)):\n",
    "    file1.writelines('/usr/src/road/damage/' + CzInJa_train[i].split(\".\")[0] + '.jpg' + \"\\n\")\n",
    "\n",
    "file1.close()\n",
    "\n",
    "file2 = open(\"../road/CzInJa_valid.txt\", \"w\")\n",
    "for i in range(len(CzInJa_valid)):\n",
    "    file2.writelines('/usr/src/road/damage/' + CzInJa_valid[i].split(\".\")[0] + '.jpg' + \"\\n\")\n",
    "\n",
    "file2.close()\n",
    "\n",
    "japanHalfLength = len(new_Japan_annoFiles)/2\n",
    "\n",
    "JaCz_train = new_Japan_annoFiles[:int(japanHalfLength)] + Czech_train\n",
    "random.shuffle(JaCz_train)\n",
    "\n",
    "file1 = open(\"../road/Ja5Cz8_train.txt\", \"w\")\n",
    "for i in range(len(JaCz_train)):\n",
    "    file1.writelines('/usr/src/road/damage/' + JaCz_train[i].split(\".\")[0] + '.jpg' + \"\\n\")\n",
    "\n",
    "file1.close()\n",
    "\n",
    "file2 = open(\"../road/Ja5Cz8_valid.txt\", \"w\")\n",
    "for i in range(len(Czech_valid)):\n",
    "    file2.writelines('/usr/src/road/damage/' + Czech_valid[i].split(\".\")[0] + '.jpg' + \"\\n\")\n",
    "\n",
    "file2.close()\n",
    "\n",
    "JaIn_train = new_Japan_annoFiles[:int(japanHalfLength)] + India_train\n",
    "random.shuffle(JaIn_train)\n",
    "\n",
    "file1 = open(\"../road/Ja5In8_train.txt\", \"w\")\n",
    "for i in range(len(JaIn_train)):\n",
    "    file1.writelines('/usr/src/road/damage/' + JaIn_train[i].split(\".\")[0] + '.jpg' + \"\\n\")\n",
    "\n",
    "file1.close()\n",
    "\n",
    "file2 = open(\"../road/Ja5In8_valid.txt\", \"w\")\n",
    "for i in range(len(India_valid)):\n",
    "    file2.writelines('/usr/src/road/damage/' + India_valid[i].split(\".\")[0] + '.jpg' + \"\\n\")\n",
    "\n",
    "file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 5-Fold split, there will be 5 dataset pair, train & valid\n",
    "# In the road directory,\n",
    "# you can use this files to make more different train / valid dataset.\n",
    "'''\n",
    "!python split_Cz.py\n",
    "!python split_In.py\n",
    "!python split_Ja.py\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Let's go with docker\n",
    "If you are not a docker user,    \n",
    "just follow to set tu the YOLOv5 from their github.    \n",
    "<https://github.com/ultralytics/yolov5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xzvf road.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo docker run --ipc=host --gpus all -it -v \"$(pwd)\"/road:/usr/src/road ultralytics/yolov5:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv /usr/src/road/road-*.yaml /usr/src/app/data/\n",
    "!mv /usr/src/road/yolov5x-road.yaml /usr/src/app/models/\n",
    "!mv /usr/src/road/road_detect.py /usr/src/app/\n",
    "!mv /usr/src/road/merge.py /usr/src/app/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N3qM6T0W53gh"
   },
   "source": [
    "# 2. Train\n",
    "I did various experiments, and I could get some good models.    \n",
    "This is just an example, there were many mixed dataset,    \n",
    "and failed weight files, too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you can't use this ipynb file in docker,    \n",
    "use just command without ! or % in the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /usr/src/app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train YOLOv5x on Czech, India and Japan road damage dataset\n",
    "!python train.py --img 704 --batch 8 --epochs 50 --data ../road/road-Cz.yaml --cfg ../road/yolov5x-road.yaml --weights yolov5x.pt\n",
    "!python train.py --img 704 --batch 8 --epochs 50 --data ../road/road-In.yaml --cfg ../road/yolov5x-road.yaml --weights yolov5x.pt\n",
    "!python train.py --img 608 --batch 16 --epochs 50 --data ../road/road-Ja.yaml --cfg ../road/yolov5x-road.yaml --weights yolov5x.pt\n",
    "\n",
    "# for improving the GPU utilization, two V100\n",
    "#!python -m torch.distributed.launch --nproc_per_node 2 train.py --img 704 --batch 8 --epochs 50 --data ../road/road-Cz.yaml --cfg ../road/yolov5x-road.yaml --weights yolov5x.pt\n",
    "#!python -m torch.distributed.launch --nproc_per_node 2 train.py --img 704 --batch 8 --epochs 50 --data ../road/road-In.yaml --cfg ../road/yolov5x-road.yaml --weights yolov5x.pt\n",
    "#!python -m torch.distributed.launch --nproc_per_node 2 train.py --img 608 --batch 16 --epochs 50 --data ../road/road-Ja.yaml --cfg ../road/yolov5x-road.yaml --weights yolov5x.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight files for inference\n",
    "#!ls /usr/src/road/road_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /usr/src/app/inference\n",
    "\n",
    "# test1\n",
    "!wget https://mycityreport.s3-ap-northeast-1.amazonaws.com/02_RoadDamageDataset/public_data/IEEE_bigdata_RDD2020/test1.tar.gz\n",
    "# test2\n",
    "!wget https://mycityreport.s3-ap-northeast-1.amazonaws.com/02_RoadDamageDataset/public_data/IEEE_bigdata_RDD2020/test2.tar.gz\n",
    "\n",
    "!tar -xzvf test1.tar.gz\n",
    "!tar -xzvf test2.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /usr/src/app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict to the labels for each country test1 dataset\n",
    "\n",
    "!python road_detect.py --source ./inference/test1/Czech/images/ --weights ../road/road_weights/Cz-1_best.pt ../road/road_weights/Cz-2_best.pt ../road/road_weights/Cz-3_best.pt ../road/road_weights/Cz-4_best.pt ../road/road_weights/Cz-5_best.pt ../road/road_weights/JaCz_best.pt --img-size 704 --conf-thres 0.4 --augment --save-txt\n",
    "!python road_detect.py --source ./inference/test1/India/images/ --weights ../road/road_weights/In-5_best.pt ../road/road_weights/JaIn_best.pt --img-size 704 --conf-thres 0.4 --augment --save-txt\n",
    "!python road_detect.py --source ./inference/test1/Japan/images/ --weights ../road/road_weights/Ja-1_best.pt ../road/road_weights/Ja-2_best.pt ../road/road_weights/Ja-3_best.pt ../road/road_weights/Ja-4_best.pt ../road/road_weights/Ja-5_best.pt ../road/road_weights/CzInJa_2_best.pt --img-size 608 --conf-thres 0.4 --augment --save-txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge them into one sampleSubmission.txt for test1\n",
    "!python merge.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict to the labels for each country test2 dataset\n",
    "\n",
    "!python road_detect.py --source ./inference/test2/Czech/images/ --weights ../road/road_weights/Cz-4_best.pt ../road/road_weights/JaCz_best.pt --img-size 704 --conf-thres 0.4 --augment --save-txt\n",
    "!python road_detect.py --source ./inference/test2/India/images/ --weights ../road/road_weights/In-5_best.pt ../road/road_weights/JaIn_best.pt --img-size 704 --conf-thres 0.4 --augment --save-txt\n",
    "!python road_detect.py --source ./inference/test2/Japan/images/ --weights ../road/road_weights/Ja-1_best.pt ../road/road_weights/Ja-2_best.pt ../road/road_weights/Ja-5_best.pt --img-size 608 --conf-thres 0.4 --augment --save-txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge them into one sampleSubmission.txt for test2\n",
    "!python merge.py"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "YOLOv5 Tutorial",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
